{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6693db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fetch_openml\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "#tratando o\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, parser='auto')\n",
    "X_raw = mnist.data.values.astype('float32') / 255.0\n",
    "y_raw = mnist.target.values.astype('int')\n",
    "\n",
    "# One-hot encoding :D Em resumo, eu faço tudo ter entre 0 e 1 para sair somente 1 em cada uma das saídas,\n",
    "# assim quando perguntado qual número é aquele, ele ativa por exemplo, o quarto número do vetor se ele\n",
    "# quiser dizer que é um número 3\n",
    "n_classes = 10\n",
    "y_one_hot = np.eye(n_classes)[y_raw]\n",
    "\n",
    "# Divisão Treino/Teste. Lembrar de machine learning\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_one_hot, train_size=10000, test_size=2000, random_state=42)\n",
    "\n",
    "class RedeNeuralMNIST:\n",
    "    def __init__(self, n_entradas, n_ocultos, n_saidas, lr=0.1):\n",
    "        self.lr = lr\n",
    "        np.random.seed(1)\n",
    "        # Inicialização\n",
    "        self.pesosEntradaOculta = np.random.randn(n_entradas, n_ocultos) * 0.1\n",
    "        self.biasEntrada = np.zeros((1, n_ocultos))\n",
    "        self.pesosOcultaSaida = np.random.randn(n_ocultos, n_saidas) * 0.1\n",
    "        self.biasSaida = np.zeros((1, n_saidas))\n",
    "\n",
    "    def sigmoide(self, x):\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def derivadaSigmoide(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.s1 = np.dot(X, self.pesosEntradaOculta) + self.biasEntrada\n",
    "        self.a1 = self.sigmoide(self.s1)\n",
    "        self.s2 = np.dot(self.a1, self.pesosOcultaSaida) + self.biasSaida\n",
    "        self.a2 = self.sigmoide(self.s2)\n",
    "        return self.a2\n",
    "\n",
    "    def train(self, X, y, epocas=1000, batch_size=128):\n",
    "        acc_history = []\n",
    "        loss_history = []\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        print(f\"Treinamento com {epocas}\")\n",
    "\n",
    "        for i in range(epocas):\n",
    "            #tirar vies e embaralhar tudo\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            # pegando só uma parte\n",
    "            for j in range(0, n_samples, batch_size):\n",
    "                X_batch = X_shuffled[j:j+batch_size]\n",
    "                y_batch = y_shuffled[j:j+batch_size]\n",
    "\n",
    "                # forward\n",
    "                a2 = self.forward(X_batch)\n",
    "\n",
    "                # backpropagation\n",
    "                erro_saida = y_batch - a2\n",
    "                delta_saida = erro_saida * self.derivadaSigmoide(a2)\n",
    "                erro_oculta = delta_saida.dot(self.pesosOcultaSaida.T)\n",
    "                delta_oculta = erro_oculta * self.derivadaSigmoide(self.a1)\n",
    "\n",
    "                # atualização dos pesos\n",
    "                self.pesosOcultaSaida += self.a1.T.dot(delta_saida) * self.lr\n",
    "                self.pesosEntradaOculta += X_batch.T.dot(delta_oculta) * self.lr\n",
    "                self.biasSaida += np.sum(delta_saida, axis=0, keepdims=True) * self.lr\n",
    "                self.biasEntrada += np.sum(delta_oculta, axis=0, keepdims=True) * self.lr\n",
    "\n",
    "            # armazenando pros gráficos\n",
    "            if i % 10 == 0:\n",
    "                predicao = self.forward(X)\n",
    "                loss = np.mean(np.square(y - predicao))\n",
    "                acc = np.mean(np.argmax(predicao, axis=1) == np.argmax(y, axis=1))\n",
    "\n",
    "                acc_history.append(acc)\n",
    "                loss_history.append(loss)\n",
    "\n",
    "                # cada 25 epocas printa o erro.\n",
    "            if i % 25 == 0:\n",
    "                print(f\"Época {i}/{epocas} - Erro: {loss:.4f} - Acurácia: {acc*100:.2f}%\")\n",
    "\n",
    "        return loss_history, acc_history\n",
    "\n",
    "nn_mnist = RedeNeuralMNIST(n_entradas=784, n_ocultos=32, n_saidas=10, lr=0.01)\n",
    "loss, acc = nn_mnist.train(X_train, y_train, epocas=200, batch_size=64)\n",
    "\n",
    "predicoes_prob = nn_mnist.forward(X_test)\n",
    "predicoes_finais = np.argmax(predicoes_prob, axis=1)\n",
    "labels_reais = np.argmax(y_test, axis=1)\n",
    "\n",
    "acc_test = np.mean(predicoes_finais == labels_reais)\n",
    "print(f\"Acurácia Final no Teste: {acc_test*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Gráfico 1: Erro\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(loss, label='Erro (MSE)', color='blue', linewidth=2)\n",
    "plt.title(\"Redução do Erro\")\n",
    "plt.xlabel(\"Iterações (x10)\")\n",
    "plt.ylabel(\"Erro\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 2: Acurácia\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(acc, label='Acurácia', color='orange', linewidth=2)\n",
    "plt.title(\"Aumento da Acurácia\")\n",
    "plt.xlabel(\"Iterações (x10)\")\n",
    "plt.ylabel(\"Taxa de Acerto\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 3: Matriz de Confusão\n",
    "plt.subplot(2, 3, 3)\n",
    "cm = confusion_matrix(labels_reais, predicoes_finais)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.xlabel(\"Previsto\")\n",
    "\n",
    "# Imagens de Teste/Não tem utilidade real\n",
    "rng = np.random.default_rng()\n",
    "indices_teste = rng.choice(len(X_test), 6, replace=False)\n",
    "\n",
    "for i, idx in enumerate(indices_teste):\n",
    "    plt.subplot(2, 6, 7 + i)\n",
    "\n",
    "    img = X_test[idx].reshape(28, 28)\n",
    "    pred = predicoes_finais[idx]\n",
    "    real = labels_reais[idx]\n",
    "\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "    cor = 'green' if pred == real else 'red'\n",
    "    plt.title(f\"P: {pred} / R: {real}\", color=cor, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, parser='auto')\n",
    "X_raw = mnist.data.values.astype('float32') / 255.0\n",
    "y_raw = mnist.target.values.astype('int')\n",
    "n_classes = 10\n",
    "y_one_hot = np.eye(n_classes)[y_raw]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_one_hot, train_size=10000, test_size=2000, random_state=42)\n",
    "\n",
    "class RedeNeuralMNIST:\n",
    "    def __init__(self, n_entradas, n_ocultos, n_saidas, lr=0.1):\n",
    "        self.lr = lr\n",
    "        np.random.seed(2)\n",
    "        self.pesosEntradaOculta = np.random.randn(n_entradas, n_ocultos) * 0.1\n",
    "        self.biasEntrada = np.zeros((1, n_ocultos))\n",
    "        self.pesosOcultaSaida = np.random.randn(n_ocultos, n_saidas) * 0.1\n",
    "        self.biasSaida = np.zeros((1, n_saidas))\n",
    "\n",
    "    def sigmoide(self, x):\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def derivadaSigmoide(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.s1 = np.dot(X, self.pesosEntradaOculta) + self.biasEntrada\n",
    "        self.a1 = self.sigmoide(self.s1)\n",
    "        self.s2 = np.dot(self.a1, self.pesosOcultaSaida) + self.biasSaida\n",
    "        self.a2 = self.sigmoide(self.s2)\n",
    "        return self.a2\n",
    "\n",
    "    def train(self, X, y, epocas=1000, batch_size=128):\n",
    "        accHistorico = []\n",
    "        perdaHistorico = []\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        for i in range(epocas):\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            for j in range(0, n_samples, batch_size):\n",
    "                X_batch = X_shuffled[j:j+batch_size]\n",
    "                y_batch = y_shuffled[j:j+batch_size]\n",
    "\n",
    "                a2 = self.forward(X_batch)\n",
    "\n",
    "                erro_saida = y_batch - a2\n",
    "                delta_saida = erro_saida * self.derivadaSigmoide(a2)\n",
    "\n",
    "                erro_oculta = delta_saida.dot(self.pesosOcultaSaida.T)\n",
    "                delta_oculta = erro_oculta * self.derivadaSigmoide(self.a1)\n",
    "\n",
    "                self.pesosOcultaSaida += self.a1.T.dot(delta_saida) * self.lr\n",
    "                self.pesosEntradaOculta += X_batch.T.dot(delta_oculta) * self.lr\n",
    "                self.biasSaida += np.sum(delta_saida, axis=0, keepdims=True) * self.lr\n",
    "                self.biasEntrada += np.sum(delta_oculta, axis=0, keepdims=True) * self.lr\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                predicao = self.forward(X)\n",
    "                loss = np.mean(np.square(y - predicao))\n",
    "                acc = np.mean(np.argmax(predicao, axis=1) == np.argmax(y, axis=1))\n",
    "                accHistorico.append(acc)\n",
    "                perdaHistorico.append(loss)\n",
    "                print(f\"Época {i} - Erro: {loss:.4f} - Acurácia: {acc*100:.2f}%\")\n",
    "\n",
    "        return perdaHistorico, accHistorico\n",
    "\n",
    "nn_mnist = RedeNeuralMNIST(n_entradas=784, n_ocultos=32, n_saidas=10, lr=0.01)\n",
    "\n",
    "loss, acc = nn_mnist.train(X_train, y_train, epocas=100, batch_size=64)\n",
    "\n",
    "predicoes = nn_mnist.forward(X_test)\n",
    "acc_test = np.mean(np.argmax(predicoes, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(f\"Acurácia no Teste: {acc_test*100:.2f}%\")\n",
    "\n",
    "print(f\"Acurácia no Teste: {acc_test*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss, label='Erro (MSE)', color='blue')\n",
    "plt.title(\"Redução do Erro\")\n",
    "plt.xlabel(\"Iterações\")\n",
    "plt.ylabel(\"Erro Médio\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "indices_teste = np.random.randint(0, len(X_test), 5)\n",
    "\n",
    "for i, idx in enumerate(indices_teste):\n",
    "    plt.subplot(2, 5, 6 + i)\n",
    "\n",
    "    img = X_test[idx].reshape(28, 28)\n",
    "    pred = np.argmax(predicoes[idx])\n",
    "    real = np.argmax(y_test[idx])\n",
    "\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "\n",
    "    cor_texto = 'green' if pred == real else 'red'\n",
    "    plt.title(f\"P: {pred} / R: {real}\", color=cor_texto, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
